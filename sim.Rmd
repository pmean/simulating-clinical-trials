---
title: "Simulating clinical trials"
author: "Steve Simon"
date: "March 22, 2017"
output: html_document
---

```{r preliminaries, echo=FALSE, message=FALSE, warning=FALSE}
library(broom)
library(dplyr)
library(ggplot2)
library(knitr)
library(magrittr)
library(rjags)
library(rstan)
library(tidyr)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
opts_chunk$set(
  echo=FALSE,
  message=FALSE,
  warning=FALSE,
  fig.width=5,
  fig.height=1)
```


## Gamma Poisson models

From this point onward, we'll summarize the simulations using boxplots and scatterplots, but it's worth remembering that what we are actually simulating is random paths.

Let's also focus on simulations of the total sample size. In a Bayesian perspective, this is a Gamma Poisson model. The Poisson distribution models patient counts and a Gamma distribution restricts the rate parameter of the Poisson to a reasonable range.

Here is code in Stan (running inside of R) that simulates the results of a clinical trial with a target goal of 350 patients in 3 years (1095 days) and places a range of uncertainty on the accrual rate that is characterized by a gamma(175, 547.5). This is a prior distribution with a strength roughly equal to half the target sample size.

```{r gamma-poisson-before-trial, fig.width=7, fig.height=1}
f <- "gamma-poisson.stan"
# set n, t to zero before the trial starts
dat_before <- list(N=350, T=3*365, S=0.5, n=0, t=0)
fit_gp1 <- stan(file=f,
  data=dat_before, iter= 10000, warmup=1000, chains = 4)
# Here's what's hiding in the file 
cat(readLines(f), sep="\n")

fit_gp1              %>%
  as.data.frame      %>%
  mutate(i="prior estimate") -> sim_gp1
```

```{r gamma-poisson-boxplot1, fig.width=7, fig.height=1}
# Boxplot of total sample size
sim_gp1                                  %>%
  ggplot(aes(i, Nstar))                   +
  expand_limits(y=0)                      +
  ylab("Estimated total sample size")     + 
  xlab(" ")                               +
  geom_boxplot()                          +
  expand_limits(y=0)                      +
  coord_flip()                           -> boxplot_gp1
print(boxplot_gp1)
```

You can learn a lot by looking at how the estimated total sample size relates to the prior paramter(s). 

Recall that in this simulation, you randomly select an accrual rate, gamma, and then you simulate a path based on that value of lambda. Not too surprisingly, the sample size depends on what lambda is chosen, though there is some variation, even for the same value of lambda.

```{r gamma-poisson-scatterplot1, fig.width=5, fig.height=5}
# Scatterplot of accrual rate versus total sample size
sim_gp1                                       %>%
  ggplot(aes(Nstar, 30*lambda))                 +
  geom_point()                                  +
  xlab("Estimated total sample size")           + 
  ylab("Accrual rate")                          +
  coord_flip()
```

With a plot like this, you can run some sensitivity checks, such as "what would happen if the accrual rate were closer to 8.5 patients per month"

```{r gamma-poisson-scatterplot2, fig.width=5, fig.height=5}
# Scatterplot of accrual rate versus total sample size
sim_gp1                                       %>%
  mutate(h=(30*lambda>8.45)*(30*lambda<8.55)) %>%
  mutate(lambda=ifelse(h==0, lambda, 8.5/30)) %>%
  arrange(h)                                  %>%
  ggplot(aes(Nstar, 30*lambda))                 +
  xlab("Estimated total sample size")           + 
  ylab("Accrual rate")                          +
  geom_point(aes(color=factor(h)))              +    
   theme(legend.position="none")                +
  coord_flip()                                  +
  scale_color_manual(values=c("gray90", "red"))
```

The key reason that you should run your simulations in Stan is that you can make a seamless transition to a simulation of a clinical trial during the trial itself. In this trial, the early accrual rate was much lower than expected. After 239 days, you have only gotten 41 patients. If you were on target, you would have 239/1095*350 = `r round(239/1095*350)` patients by now. HOw much is this shortfall hurting us?

```{r gamma-poisson-during-trial, fig.width=5, fig.height=1.33}
f <- "gamma-poisson.stan"
dat_during <- list(N=350, T=3*365, S=0.5, n=41, t=239)
fit_gp2 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)

fit_gp2              %>%
  as.data.frame      %>%
  mutate(i="updated estimate") %>%
  bind_rows(sim_gp1) -> sim_gp2

# Boxplot of total sample size
sim_gp2                                  %>%
  ggplot(aes(i, Nstar))                   +
  expand_limits(y=0)                      +
  ylab("Estimated total sample size")     + 
  xlab(" ")                               +
  geom_boxplot()                          +
  coord_flip()
```

For this trial, you were able to get 341 patients, but it took a lot longer than you expected, 1336 days instead of 1095 days. Time to get ready for your next clinical trial. NOT SO FAST! You are not done with simulations when the trial is over. After the trial, take a look at how your accrual rate ranks relative to the range of accrual rates associated with your prior distribution.

```{r gamma-poisson-after-trial, echo=FALSE, fig.width=5, fig.height=1.67}
data.frame(
  i="final estimate",
  lambda=341 / 1336,
  stringsAsFactors=FALSE) %>%
  bind_rows(sim_gp1)      -> sim_gp3

sim_gp1$lambda                           %>%
  is_less_than(341 / 1336)               %>%
  mean                                   %>%
  multiply_by(100)                       %>%
  round(1)                               %>%
  paste("Final estimate is at the", .)   %>%
  paste("percentile")                    -> pctl

# Boxplot of total sample size
sim_gp3                                  %>%
  ggplot(aes(i, lambda*30))               +
  ylab("patients per month")              + 
  xlab(" ")                               +
  geom_boxplot()                          +
  ggtitle(pctl)                           +
  coord_flip()
```

Okay, so you were way off. No one is going to hang you. If the same thing occurs over and over again, though, let's talk.

## Early predictions

The commonly cited objection to informative priors is that they can bias the research. Whether that is true or not in a hypothesis testing framework is a matter of open debate. But using informative priors for operational characteristics of a study will not bias any resulting hypothesis tests.

While most Bayesian models use flat, non-informative, or only weakly informative prior distributions, when you are simulating the operational features of a clinical trial, you need to be bold and use strong informative prior distributions. There are three reasons for this.

First, if the best you can do for accrual rates for a clinical trial is a flat prior, what you are really saying is that you think you might see a couple of patients every day, or maybe a couple of patients every year, and you really don't have a strong belief of one of these accrual rates over another. Anyone who can only predict accrual rates across such a wide range is unqualified to run a clinical trial.

Second, if you run a simulation with a flat prior before the trial starts, you get results with an unrealisticly wide range.

Third, a strong prior distribution provides you with stable estimates early in the clinical trial. This is worth an illustration.

```{r very-flat-prior-bayesian-average}
# stan is inefficient for these next couple of models, but I'm not
# sure why. It is easy enough to run a simulation directly.
n_reps <- 100000
pts <- unlist(read.csv("count.csv"))
x <- cumsum(pts)
T <- 3*365
N <- 350
S <- 0.001 / N
alpha.prior <- N*S
beta.prior  <- T*S
nx <- length(x)
very_flat_predictions <- data.frame(t <- 1:nx, lo=rep(0,nx), hi=rep(0,nx))
for (i in seq(1, nx, by=1)) {
  alpha.posterior <- alpha.prior + x[i]
  beta.posterior  <- beta.prior + i
  lambda <- rgamma(n_reps, alpha.posterior, beta.posterior)
  waiting_time <- i + rgamma(n_reps, N-x[i], lambda)
  qx <- quantile(waiting_time, probs=c(0.05, 0.95))
  very_flat_predictions[i, 2:3] <- qx
}
```

```{r plot-very-flat, fig.width=4, fig.height=4}
# split from the chiunk above to save time during testing
very_flat_predictions                           %>%
  mutate(lo=lo/365)                             %>%
  mutate(hi=hi/365)                             %>%
  ggplot(aes(x=t, ymin=lo, ymax=hi))             +
  geom_ribbon(alpha=0.2)                         +
  geom_line(aes(x=t, y=hi))                      +
  geom_line(aes(x=t, y=lo))                      +
  ggtitle("Predictions from flat prior")         +
  ylab("Estimated trial duration (years)")       +
  xlab("Date of prediction (days)")
```

This is possibly an unfair example because the trial had a slow start. But it takes more than 100 days into the trial to get a decent estimate of the upper bound. The first three predictions are a measure of how unstable things are. On the first day, you have recruited one patient, and the upper limit is estimated at `r round(very_flat_predictions$hi[1]/365)` years. On the second day, no one shows up, so your upper limit jumps to `r round(very_flat_predictions$hi[2]/365)` years. On the third day, one patient shows up, so your upper limit plummets to `r round(very_flat_predictions$hi[3]/365)` years.

Compare this to the predictions that use an informative prior. The posterior estimate in a Bayesian model with an informative prior is a weighted average of the prior distribution and the data, and that weighted average leans very heavily on the prior distribution early in the trial.

```{r bayesian-average}
n_reps <- 100000
pts <- unlist(read.csv("count.csv"))
x <- cumsum(pts)
T <- 3*365
N <- 350
S <- 0.5
alpha.prior <- N*S
beta.prior  <- T*S
nx <- length(x)
informative_predictions <- data.frame(t <- 1:nx, lo=rep(0,nx), hi=rep(0,nx))
for (i in seq(1, nx, by=1)) {
  alpha.posterior <- alpha.prior + x[i]
  beta.posterior  <- beta.prior + i
  lambda <- rgamma(n_reps, alpha.posterior, beta.posterior)
  waiting_time <- i + rgamma(n_reps, N-x[i], lambda)
  qx <- quantile(waiting_time, probs=c(0.05, 0.95))
  informative_predictions[i, 2:3] <- qx
}
```

```{r plot-informative}
informative_predictions %>%
  mutate(lo=lo/365)                             %>%
  mutate(hi=hi/365)                             %>%
  ggplot(aes(x=t, ymin=lo, ymax=hi))             +
  geom_ribbon(alpha=0.2)                         +
  geom_line(aes(x=t, y=hi))                      +
  geom_line(aes(x=t, y=lo))                      +
  ggtitle("Predictions from informative prior")  +
  ylab("Estimated trial duration (years)")       +
  xlab("Date of prediction (days)")
```

## Hedging priors

One problem with informative prior distributions is that many researchers get them wrong. They are either too optimistic about the accrual rate, or they think they know the accrual rate with more certainty than they actually do, or sometimes both.

You can minimize the problems associated with a bad informative prior by adding a hedging hyperparameter.

```{r hedging-extension}
# hedging posterior
f <- "hedging-extension.stan"
# Here's what's hiding in the file 
cat(readLines(f), sep="\n")
dat_during <- list(N=350, T=3*365, S=0.5, n=41, t=239)
fit_hd2 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_hd2                                         %>%
  as.data.frame                                 %>%
  mutate(i="hedging update")                    -> sim_hd2
```

```{r recalculate-informative-prior}
# informative prior
f <- "gamma-poisson.stan"
dat_during <- list(N=350, T=3*365, S=0.5, n=0, t=0)
fit_gp1 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_gp1                                         %>%
  as.data.frame                                 %>%
  mutate(i="prior estimate")                    -> sim_gp1
```

```{r recalculate-informative-update}
# informative posterior
f <- "gamma-poisson.stan"
dat_during <- list(N=350, T=3*365, S=0.5, n=41, t=239)
fit_gp2 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_gp2                                         %>%
  as.data.frame                                 %>%
  mutate(i="informative update")             -> sim_gp2
```

```{r calculate-flat-update}
# flat posterior
f <- "gamma-poisson.stan"
dat_during <- list(N=350, T=3*365, S=0.001/350, n=41, t=239)
fit_fl2 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_fl2                                         %>%
  as.data.frame                                 %>%
  mutate(i="flat update") -> sim_fl2
```

```{r calculate-data-projection}
# data
sim_dat <- data.frame(lambda=41/239, Nstar=41+(1095-239)*(41/239), i="data projection")
```

```{r hedging-boxplots, fig.width=5, fig.height=1.67}
# Boxplot of total sample size
sim_hd2                                         %>%
  bind_rows(sim_gp1)                            %>%
  bind_rows(sim_dat)                            %>%
  ggplot(aes(i, Nstar))                          +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

Notice that the large discrepancy with a pure data projection versus the informative prior. When there is a discrepancy, the hedging hyperprior will strongly downweight the informative prior.

The following boxplot shows how much the hedging hyperparameter downweighted the prior distribution

```{r downweight, fig.height=1, fig.width=5}
sim_hd2 %>%
  mutate(i=" ")                                 %>%
  ggplot(aes(i, pi))                             +
  expand_limits(y=c(0,2))                        +
  ylab("Hedging hyperparameter")                 + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

If you compared this to a flat prior, you would see that the flat prior would line up perfectly with the data projection.

```{r compare-to-flat, fig.width=7, fig.height=1.67}
# Boxplot of total sample size
sim_fl2                                         %>%
  bind_rows(sim_gp1)                            %>%
  bind_rows(sim_dat)                            %>%
  ggplot(aes(i, Nstar))                          +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

A non-Bayesian solution would probably also line up perfectly with the data projection.

```{r compare-to-informative, fig.width=7, fig.height=1.67}
sim_gp2                                         %>%
  bind_rows(sim_gp1)                            %>%
  bind_rows(sim_dat)                            %>%
  ggplot(aes(i, Nstar))                          +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

Let's look at the behavior of the hedging hyperprior when it's not needed--when the trial is actually slightly ahead of schedule (41 patients in 129 days).

```{r hedging-extension2}
# hedging posterior
f <- "hedging-extension.stan"
dat_during <- list(N=350, T=3*365, S=0.5, n=41, t=129)
fit_hd4 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_hd4                                         %>%
  as.data.frame                                 %>%
  mutate(i="hedging posterior")                 -> sim_hd4
```

```{r informative-prior2}
# informative prior
f <- "gamma-poisson.stan"
dat_before <- list(N=350, T=3*365, S=0.5, n=0, t=0)
fit_gp4 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_gp4                                         %>%
  as.data.frame                                 %>%
  mutate(i="informative prior")                 -> sim_gp4
```

```{r informative-update2}
# informative posterior
f <- "gamma-poisson.stan"
dat_during <- list(N=350, T=3*365, S=0.5, n=41, t=129)
fit_gp5 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_gp5                                         %>%
  as.data.frame                                 %>%
  mutate(i="informative posterior")             -> sim_gp5
```

```{r flat-update2}
# flat posterior
f <- "gamma-poisson.stan"
dat_during <- list(N=350, T=3*365, S=0.001/350, n=41, t=129)
fit_fl3 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
fit_fl3                                         %>%
  as.data.frame                                 %>%
  mutate(i="flat posterior")                    -> sim_fl3
```

```{r data-projection2}
# data
sim_dat <- data.frame(lambda=41/239, Nstar=41+(1095-129)*(41/129), i="Data")
```

```{r hedging-boxplot2, fig.width=7, fig.height=1.67}
# Boxplot of total sample size
sim_hd4                                         %>%
  bind_rows(sim_gp4)                            %>%
  bind_rows(sim_dat)                            %>%
  ggplot(aes(i, Nstar))                          +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

```{r hedging-boxplot3, fig.width=7, fig.height=1.67}
# Boxplot of total sample size
sim_fl3                                         %>%
  bind_rows(sim_gp4)                            %>%
  bind_rows(sim_dat)                            %>%
  ggplot(aes(i, Nstar))                          +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

```{r hedging-boxplot4, fig.width=7, fig.height=1.67}
# Boxplot of total sample size
sim_gp5                                         %>%
  bind_rows(sim_gp4)                            %>%
  bind_rows(sim_dat)                            %>%
  ggplot(aes(i, Nstar))                          +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```
The following boxplot shows how much the hedging hyperparameter downweighted the prior distribution. In this case, the data actually upweighted the prior slightly on average. Think of it as a reward for choosing your prior distribution so well. 

There's a technical fix that you can make so that the mean of the hyperparameter never exceeds 1, but we won't talk about it here.

```{r downweight2, fig.height=1, fig.width=7}
sim_hd4 %>%
  mutate(i=" ")                          %>%
  ggplot(aes(i, pi))                      +
  expand_limits(y=c(0,2))                 +
  ylab("Hedging hyperparameter")          + 
  xlab(" ")                               +
  geom_boxplot()                          +
  coord_flip()
```

## Formulas for accrual delays

There are several different models for accrual delays. They may or may not include a start-up time before ANY accrual, and they may or may not include a warm-up time early in the trial when accrual is slower. If there is a warm-up time, there are several ways to model the transition from slow accrual to full accrual.

```{r delay-example0, fig.height=1.5, fig.width=7}
data.frame(x=c(100, 200), y=c(100, 200))             %>%
  ggplot(aes(x, y))                                   +
  geom_point(color="white")                           +
  labs(x=NULL, y=NULL)                                +
  geom_segment(x   =100, y   =150, 
               xend=120, yend=150,
               color="red", size=3)                   +
  geom_segment(x   =100, y   =150, 
               xend=120, yend=150,
               color="gray", size=1)                  +
  geom_label  (x=110, y=125, fill="red", 
               label="Waiting\nto start")             +
  geom_label  (x=135, y=125, fill="yellow",
               label="Slow\naccrual")                 +
  geom_segment(x   =150, y   =200,
               xend=200, yend=200,
               color="green", size=3,
               arrow=arrow(length=unit(0.1, "inch"))) +
  geom_segment(x   =150, y   =200,
               xend=200, yend=200,
               color="gray", size=1, alpha=0.5,
               arrow=arrow(length=unit(0.1, "inch"))) +
  geom_label  (x=160, y=125, fill="green",
               label="Full\naccrual")                 + 
  theme(plot.margin=unit(c(0,0,0,0),"in"))            +
  theme(axis.line =element_blank())                   +
  theme(axis.text =element_blank())                   +
  theme(axis.ticks=element_blank())                   +
  theme(axis.title=element_blank())                  -> delay_graph
```

Here's a linear transition from slow to full accrual. It has two parameters, the duration of the waiting to start period and the duration of the transition to full accrual.
 
```{r delay-example1, fig.height=1.5, fig.width=7}
delay_graph                                      +
  geom_segment(x   =120, y   =150,
               xend=150, yend=200,
               color="yellow", size=3)           +
  geom_segment(x   =120, y   =150,
               xend=150, yend=200,
               color="gray", size=1)
```

Here's a discontinuous transition from slow to full accrual. It has three parameters, the duration of the waiting to start period, the rate during slow accrual, and the duration of the transition to full accrual.
 
```{r delay-example2, fig.height=1.5, fig.width=7}
delay_graph                                      +
  geom_segment(x   =120, y   =180,
               xend=150, yend=180,
               color="yellow", size=3)           +
  geom_segment(x   =120, y   =180,
               xend=150, yend=180,
               color="gray", size=1)
  
```

Here's a partially discontinuous transition from slow to full accrual. It has the same three parameters as the earlier example, but the implementation is slightly different.
 
```{r delay-example3, fig.height=1.5, fig.width=5}
delay_graph                                      +
  geom_segment(x   =120, y   =180,
               xend=150, yend=200,
               color="yellow", size=3)           +
    geom_segment(x   =120, y   =180,
               xend=150, yend=200,
               color="gray", size=1)
```

Here's a smooth transition using the function 3x^2-2x^3.
 
```{r delay-example4, fig.height=1.5, fig.width=5}
x_original <- seq(0, 1, length=50)
y_original <- 3*x_original^2-2*x_original^3
x_rescaled <- 120 + 30 * x_original
y_rescaled <- 150 + 50 * y_original
df2 <- data.frame(x=x_rescaled, y=y_rescaled)
delay_graph                                      +
  geom_path(aes(x, y), data=df2,
            color="yellow", size=3)              +
  geom_path(aes(x, y), data=df2,
            color="gray",  size=1)
```

## Priors for a delay model

We'll fit the discontinuous model, the second one shown, because it is convenient, but there are probably very few practical differences among these models. The discontinuous model has three parameters. Delta1 represents the duration of time waiting for the trial to start as a fraction of the total time planned. Delta2 represents the ratio of the accrual rate during the slow accrual period and the accrual rate during the full accrual period. Delta3 represents the duration of time for the slow accrual period as a fraction of the total time planned.

Generally, you should use strong priors here to limit delta1 and delta3 to the lower end of the range from 0 to 1. If you really thought that delta1 and/or delta3 would be much closer to 1, then you should rethink what your total time planned should be.

Here's some possible prior distributions. For delta1, the proportion of the total planned time that you spend waiting for the study to get started, a beta(7, 63) corresponds to an expectation that 10% of the time will be lost on average. The total weight assigned to this prior (70) corresponds to S=0.2.

```{r delay-priors1, fig.height=1.67, fig.width=7}
s_list <- c(0.1, 0.2, 0.5)
n_s <- length(s_list)
n_reps <- 1000
S1 <- rep(s_list, each=n_reps)
N=350
D1 <- 0.1
N <- 350
dp1 <- data.frame(S1=paste("S1 =", S1),
  delta1=rbeta(n_s*n_reps, S1*N*D1, S1*N*(1-D1)))
# units conversion
dp1                                             %>%
  mutate(delta1=T*delta1/30)                    %>%
  ggplot(aes(factor(S1), delta1))                +
  geom_boxplot(color=c("gray", "black", "gray")) +
  xlab(" ")                                      + 
  ylab("Months waiting to start")                +
  coord_flip()
```

For delta2, the proportionate reduction in accrual during the warm-up period, a beta(14, 21) corresponds to an expectation that the reductiton during warm-up will be about 40% of the regular accrual rate on average. The total weight assigned to this prior (35) is weaker and corresponds to S=0.1.

```{r delay-priors2, fig.height=1.67, fig.width=5}
s_list <- c(0.1, 0.2, 0.5)
n_s <- length(s_list)
n_reps <- 1000
S2 <- rep(s_list, each=n_reps)
N <- 350
D2 <- 0.4
dp2 <- data.frame(S2=S2,
  delta2=rbeta(n_s*n_reps, S2*N*D2, S2*N*(1-D2)))
# units conversion
dp2                                             %>%
  mutate(delta2=30*N/T*delta2)                  %>%
  ggplot(aes(factor(S2), delta2))                +
  geom_boxplot(color=c("black", "gray", "gray")) +
  xlab(" ")                                      +
  ylab("Accrual rate per month during warm-up")  +
  coord_flip()
```

For delta3, the proportion of the total planned time that you spend in the warm-up period, a beta(11.9, 58.1) corresponds to an expectation that 17% of the time your trial will be stuck in the warm-up phase. The total weight assigned to this prior (70) corresponds to S=0.2.

```{r delay-priors3, fig.height=1.67, fig.width=5}
s_list <- c(0.1, 0.2, 0.5)
n_s <- length(s_list)
n_reps <- 1000
S3 <- rep(s_list, each=n_reps)
N <- 350
D3 <- 0.17
dp3 <- data.frame(S3=S3, delta3=rbeta(n_s*n_reps, S3*N*D3, S3*N*(1-D3)))
# units conversion
dp3                                             %>%
  mutate(delta3=T*delta3/30)                    %>%
  ggplot(aes(factor(S3), delta3))                +
  geom_boxplot(color=c("gray", "black", "gray")) +
  xlab(" ")                                      +
  ylab("Months in slow accrual")                 +
  coord_flip()
```

## Fitting a delay model

First look at what these priors do to the total sample size.

```{r delay-after, fig.height=1, fig.width=5, eval=FALSE}
f <- "beta-extension.stan"
# Here's what's hiding in the file 
cat(readLines(f), sep="\n")
dat_before <- list(N=350, T=3*365, S=0.5, D1=0.1, S1=0.2, D2=0.4, S2=0.1, D3=0.17, S3=0.2)
fit_d31 <- stan(file=f,
  data=dat_before, iter= 1000, chains = 4)

fit_d31              %>%
  as.data.frame      %>%
  mutate(i="before") -> sim_d31
# Boxplot of total sample size
sim_d31                                  %>%
  ggplot(aes(i, Nstar))                   +
  expand_limits(y=0)                      +
  ylab("Estimated total sample size")     + 
  xlab(" ")                               +
  geom_boxplot()                          +
  coord_flip()
```

You should consider exploring how sensitive your estimated total sample size is relative to each of the delay parameters.

```{r delay-part2, fig.width=5, fig.height=5, eval=FALSE}
sim_d31                                         %>%
  ggplot(aes(delta1, Nstar))                     +
  ylab("Estimated total sample size")            + 
  xlab("Proportion of time waiting to start")    +
  geom_point()

sim_d31                                         %>%
  ggplot(aes(delta2, Nstar))                     +
  ylab("Estimated total sample size")            + 
  xlab("Accrual reduction during warm-up")       +
  geom_point()

sim_d31                                         %>%
  ggplot(aes(delta3, Nstar))                     +
  ylab("Estimated total sample size")            + 
  xlab("Proportion of time in slow accrual")     +
  geom_point()
```

It looks like the proportion of time waiting to start has a far greater influence on the total sample size than the other parameters. This would change if you changed your prior distributions, of course, but in general it makes sense. Time lost waiting for the trial to start is time when no subjects enter. Time during slow accrual is important but at least you are getting some subjects in during this time frame. The relative slowness during the warm-up period is also not too critical.

The actual trial that I have used so far did not have a formal model for delays, but it is easy enough to modify the data to fit this example. You need to prepend the data with a string of zeros corresponding to the days when the trial was waiting to get started. The day with the first non-zero entry is considered to be the end of the waiting and the beginning of the warm-up period. The end of the warm-up period is unknown, even after the trial is over, but can be estimated by the daily accrual pattern.

```{r delay-during}
pts <- as.numeric(c(rep(0, 58), unlist(read.csv("count.csv"))))
data=list(N=350, T=3*365, S=0.5, T0=58,
          D1=0.1,  S1=0.2,
          D2=0.4,  S2=0.1,
          D3=0.17, S3=0.2,
          t=length(pts), n=pts)
inits = list(lambda=0.3, delta2=0.15, delta3=0.15)
pts.m <- jags.model("delay1-extension.jags", data=data, inits=inits,
  n.adapt = 100)

parms <- c("lambda", "delta1", "delta2", "delta3", "Nstar")
pts.samp <- coda.samples(pts.m, var=parms, n.iter = 1000)
summary(pts.samp)
pts.matrix <- as.matrix(pts.samp)
nm <- dimnames(pts.matrix)[[2]]
hist(pts.matrix[, "Nstar"], breaks=50, main=nm[1])
hist(1095*pts.matrix[, "delta1"]/30, breaks=50, main=nm[2])
hist(1095*pts.matrix[, "delta2"], breaks=50, main=nm[3])
hist(1095*pts.matrix[, "delta3"]/30, breaks=50, main=nm[4])
hist(pts.matrix[, "lambda"], breaks=50, main=nm[5])
```

## Modeling exclusions and refusals

There's a gauntlet that patients must travel through before they are officially part of your clinical trial. As you ask them questions, you will find that some of the patients might not meet all of your inclusion criteria. Also, the patients may change their minds, after hearing the details of your clinical trial, and decide that they don't really want to participate after all.

You can model these two processes using binomial distributions.

Here's some possible prior distributions.

```{r binomial-priors1, fig.height=1.5, fig.width=5}
P1 <- 0.9
S1 <- 0.2
N <- 350
dp1 <- data.frame(S1=S1, y=rbeta(1000, S1*N*P1, S1*N*(1-P1)))

ggplot(dp1, aes(factor(S1), y)) +
  geom_boxplot() +
  labs(x="", y="Proportion meeting inclusion criteria") +
  coord_flip()
```

```{r binomial-priors2, fig.height=1.5, fig.width=5}
P2 <- 0.7
S2 <- 0.1
dp2 <- data.frame(S2=S2, y=rbeta(1000, S2*N*P2, S2*N*(1-P2)))

ggplot(dp2, aes(factor(S2), y)) +
  geom_boxplot() +
  labs(x="", y="Proportion consenting") +
  coord_flip()
```

If you do a simple extrapolation, the total sample size after exclusions and refusals should be about `r 100*P1*P2`% of the 350 planned patients or `r N*P1*P2` patients.

```{r binomial, fig.height=1.67, fig.width=5}
f <- "binomial-extension.stan"
# Here's what's hiding in the file 
cat(readLines(f), sep="\n")
dat_before <- list(N=350, T=3*365, S=0.5, 
                   n=0, t=0, 
                   P1=0.9, S1=0.2, P2=0.7, S2=0.1,
                   n1=0, n2=0, n3=0)
fit_bi1 <- stan(file=f,
  data=dat_before, iter= 1000, chains = 4)

tidy(fit_bi1, conf.int=TRUE)

fit_bi1                                         %>%
  as.data.frame                                 %>%
  mutate(i="before") -> sim_bi1
# Boxplot of total sample size
sim_bi1                                         %>%
  rename(total_sample=N1star)                   %>%
  rename(after_exclusions=N2star)               %>%
  rename(after_refusals=N3star)                 %>%
  gather(level, N, total_sample,
    after_exclusions, after_refusals)           %>%
  ggplot(aes(level, N, group=level))             +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

You should consider exploring how sensitive your estimated total sample size is relative to each of the binomial parameters.

```{r binomial-part2, fig.width=5, fig.height=5}
sim_bi1                                         %>%
  ggplot(aes(pi1, N3star))                       +
  ylab("Estimated total sample size")            + 
  xlab("Proportion meeting inclusion")           +
  geom_point()

sim_bi1                                         %>%
  ggplot(aes(pi2, N3star))                       +
  ylab("Estimated total sample size")            + 
  xlab("Proportion consenting")                  +
  geom_point()

```

The estimated total sample size is more sensitive to the proportion consenting, mostly because your prior beliefs gave this proportion a broader range of possibilities.

The trial that you have seen illustrated thus far did not track exclusions and refusals, but let's suppose that of the 41 patients who

```{r binomial-extension-during, fig.width=5, fig.height=1.67}
f <- "binomial-extension.stan"
dat_before <- list(N=350, T=3*365, S=0.5, 
                   P1=0.9, S1=0.2, P2=0.7, S2=0.1,
                   t=239, n1=90, n2=81, n3=41)
fit_bi1 <- stan(file=f,
  data=dat_before, iter= 1000, chains = 4)

tidy(fit_bi1, conf.int=TRUE)

fit_bi1                                         %>%
  as.data.frame                                 %>%
  mutate(i="before") -> sim_bi1

# Boxplot of total sample size
sim_bi1                                         %>%
  rename(total_sample=N1star)                   %>%
  rename(after_exclusions=N2star)               %>%
  rename(after_refusals=N3star)                 %>%
  gather(level, N, total_sample,
    after_exclusions, after_refusals)           %>%
  ggplot(aes(level, N, group=level))             +
  expand_limits(y=0)                             +
  ylab("Estimated total sample size")            + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```

The sample size estimate after refusals and exclusions is around 180 to 200, which is lower than what you were expecting prior to data collection, mostly because the proportion of refusals is a lot worse.

## Modeling multi-center trials.

Here are the accrual data on two multi-center trials. The first, csp546, has accrual at 4 centers. The study ran for 56 weeks and recruited 613 total participants. The second, csp588, has accrual at 4 centers. The study ran for 24 weeks and recruited 127 patients.

```{r read-multicenter-data}

f <- "csp546 enrollment.csv"
csp546 <- read.csv(file=f, stringsAsFactors=FALSE, header=TRUE)

csp546a <- csp546
csp546a[is.na(csp546a)] <- 0
csp546a$Z <- apply(csp546a, 1, sum)
csp546b <- as.data.frame(sapply(csp546a, cumsum))
csp546b$t <- 1:(dim(csp546b)[1])
csp546b

f <- "csp558 enrollment.csv"
csp558 <- read.csv(file=f, stringsAsFactors=FALSE, header=TRUE)

csp558a <- csp558
csp558a[is.na(csp558a)] <- 0
csp558a$Z <- apply(csp558a, 1, sum)
csp558b <- as.data.frame(sapply(csp558a, cumsum))
csp558b$t <- 1:(dim(csp558b)[1])
csp558b
```

There are several ways to model accrual in a hierarchical setting. A simple and easy to follow approach is to model deviations of each individual center from the overall accrual rate with a lognormal distribution. The lognormal distribution is a bit tricky to work. One definition of a lognormal random variable is a random variable where the logarithm of that random variable is normally distributed. So you can describe the lognormal distribution in terms of the mean, $\mu$, and standard deviation, $\sigma$, of the underlying normal distribution. Or you can describe it in terms of the geometric mean, $e^\mu$, and geometric standard deviation, $e^\sigma$.

Another tricky issue is that the arithmetic mean of a lognormal random variable is going to be larger than the geometric mean. If X is lognormal with parameters $\mu$ and $\sigma$, then the arithmetic mean is larger than the geometric mean by a multiplicative factor, $e^{0.5~\sigma^2}$.

In our setting, we want to make sure that the arithmetic mean of the lognormal center effects is always 1. So our lognormals will use a "fudge factor" of $\mu=-0.5~\sigma^2$.

```{r set_constants}
n_centers <- 14
```

It's important to anchor these prior distributions to something concrete and observable. A simple numeric summary is the proportion of patients that are likely to come from your highest accruing center. Let's look at an example with `r n_centers` centers. If the accrual rates were identical across all `r n_centers` centers, then the each center would contribute roughly `r round(100/n_centers)`% of the patients.

```{r examining-hierarchical-priors, fig.width=7, fig.height=2.67}
n_reps <- 1000

gsd_list <- c(1.1, 1.2, 1.5, 2, 4, 8)
n_gsd <- length(gsd_list)

lb <- rep(NA, n_gsd*n_reps)
max_pct <- rep(NA, n_gsd*n_reps)

j <- 0
for (gsd in gsd_list) {
  for (i in 1:n_reps) {
    j <- j+1
    eta <- rlnorm(n_centers, -0.5*log(gsd)^2, log(gsd))
    lb[j] <- paste("GSD =", gsd)
    max_pct[j] <- 100 * max(eta) / sum(eta)
  }
}
data.frame(lb, max_pct)                         %>%
  ggplot(aes(lb, max_pct))                       +
  expand_limits(y=c(0, 100))                     +
  ylab("Percent accrual in best center")         + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  geom_hline(yintercept=100/n_centers,
             color="gray")                       +
  coord_flip()
```

You decide after looking at these boxpots that a GSD around 1.5 is fairly representative of your experience with accrual in multi-center trials of this particular type and that a GSD of 2 represents the most extreme case you are likely to encounter.

Now you need to specify a prior on the GSD that is centered around 1.5 and where most of the probability is for values below 2.

```{r examining-hierarchical-priors-part2, fig.width=7, fig.height=2.67}
n_reps <- 1000
N <- 350

S1_list <- c(0.01, 0.02, 0.05, 0.1, 0.2, 0.5)
n_S1 <- length(S1_list)

lb <- rep("---", n_S1*n_reps)
gsd <- rep(NA, n_S1*n_reps)

j <- 0
for (S1 in S1_list) {
  for (i in 1:n_reps) {
    j <- j+1
    gamma <- rgamma(1, N*S1, N*S1*log(1.5)^2)
    sigma <- sqrt(1 / gamma)
    gsd[j] <- exp(sigma)
    lb[j] <- paste("S1 =", S1)
  }
}
data.frame(lb, gsd)                             %>%
  ggplot(aes(lb, gsd))                           +
  ylab("GSD")                                    + 
  xlab(" ")                                      +
  geom_boxplot()                                 +
  coord_flip()
```


```{r hierarchical-extension-before-trial}
f <- "hierarchical-extension.stan"
# Here's what's hiding in the file 
cat(readLines(f), sep="\n")
dat_before <- list(N=350, T=3*365, S=0.5, M=14,
                   S1=0.02, GSD=1.5,
                   t=0, n=rep(0, 14))
fit_h21 <- stan(file=f,
  data=dat_before, iter= 1000, chains = 4)
```

```{r hierarchical-boxplot, fig.width=7, fig.height=1}
fit_h21              %>%
  as.data.frame      %>%
  mutate(i="before") -> sim_h21
# Boxplot of total sample size
sim_h21                                  %>%
  ggplot(aes(i, Nstar))                   +
  expand_limits(y=0)                      +
  ylab("Estimated total sample size")     + 
  xlab(" ")                               +
  geom_boxplot()                          +
  coord_flip()
```

```{r hierarchical-scatterplots}
sim_h21                                         %>%
  ggplot(aes(max_pct, Nstar))                    +
  ylab("Estimated total sample size")            + 
  xlab("Proportion accrued at best site")        +
  geom_point()

sim_h21                                         %>%
  ggplot(aes(gsd, max_pct))                      +
  xlab("GSD")                                    + 
  ylab("Proportion accrued at best site")        +
  geom_point()
```

```{r}
tidy(fit_h21, conf.int=TRUE)
m <- c(14, 9, 17, 0, 11, 28, 22, 1, 12, 25, 41, 0, 27, 0)	
length(m)
t <- 14
csp546b[t, 1:14]
f <- "hierarchical-extension.stan"
dat_during <- list(N=350, T=3*365, S=0.5, M=14,
                   S1=0.02, GSD=1.5,
                   t=14, n=csp546b[t, 1:14])
fit_h22 <- stan(file=f,
  data=dat_during, iter= 1000, chains = 4)
tidy(fit_h22)
```

```{r more-hierarchical}
fit_h21              %>%
  as.data.frame      %>%
  mutate(i="before") -> sim_h21

# Boxplot of total sample size
sim_h21                                  %>%
  ggplot(aes(i, Nstar))                   +
  expand_limits(y=0)                      +
  ylab("Estimated total sample size")     + 
  xlab(" ")                               +
  geom_boxplot()                          +
  coord_flip()
```

```{r more_stuff, eval=FALSE}
# Scatterplot of accrual rate versus total sample size
sim_h21                                  %>%
  ggplot(aes(30*mu, Nstar))               +
  ylab("Estimated total sample size")     + 
  xlab("Accrual rate")                    +
  geom_point()

sim_h21                                  %>%
  ggplot(aes(scale, Nstar))               +
  ylab("Estimated total sample size")     + 
  xlab("Hierarchical spread")             +
  geom_point()
```

Final comments???